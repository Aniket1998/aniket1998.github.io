---
layout: homepage
---

## About Me

I ~~am currently~~ was a Pre-Doctoral Researcher at Google DeepMind, India. Before this, I was a dazed and confused undergrad at Indian Institute of Technology Kanpur (IITK) double majoring in Electrical Engineering and Mathematics. Towards the tail end of my life at IITK, I interned at the Max Planck Institute for Intelligent Systems (MPI-IS) under the supervision of [Michael Muehlebach](https://sites.google.com/corp/view/mmuehlebach/) and [Bernhard Schölkopf](https://is.mpg.de/~bs); and the Tata Institute of Fundamental Research under the supervision of [Sandeep Juneja](https://www.tcs.tifr.res.in/~sandeepj/)


##  Research

I'm broadly interested in the union of Probability, Geometry and Theoretical Computer Science. Specific areas of interest include:

- **Sampling and Markov Chains** : Algorithms and Lower Bounds for Sampling from High Dimensional Gibbs Measures and Convex Bodies, Spin Systems, Bakry-Emery Theory  

- **Applied Probability** : Phase Transitions in Random Structures, Information-Computation Tradeoffs in High Dimensional Statistics, Optimal Transport Theory, Interacting Particle Systems

- **Dynamical Systems and Optimization** : Euclidean and Wasserstein Gradient Flows, applications to Continuous Optimization and Statistical Learning

Much of my recent work has focused on the applications of these ideas to the analysis of widely used Machine Learning algorithms.

## News

- **[Nov. 2023]** Talk at the [MSR-IISc Theory Seminar](https://www.csa.iisc.ac.in/iisc-msr-seminar/?talk=20240809_AniketDas) on optimal linear time streaming algorithms for heavy tailed statistics   
- **[Mar. 2024]** Talk at FLAIR Seminar, EPFL on analyzing sampling as optimization on the space of measures
- **[Nov. 2023]** [Talk](https://www.youtube.com/watch?v=ufDU59FSCls) at the [MSR-IISc Theory Seminar](https://www.csa.iisc.ac.in/iisc-msr-seminar/?talk=20231124_AniketDas) on analyzing sampling through the lens of optimization.  
- **[Sept. 2023]** Paper on [Fast Finite-Particle Convergence of Stein Variational Gradient Descent](https://arxiv.org/abs/2305.17558) accepted as a **Spotlight Paper at NeurIPS 2023**
- **[May 2023]** Papers on [Stochastic Gradient Langevin Dynamics](https://proceedings.mlr.press/v195/das23a.html) and [Near Optimal Heteroscedastic Regression](https://proceedings.mlr.press/v195/das23b.html) accepted at **COLT 2023**. 
- **[Sep. 2022]** Paper on [Sampling Without Replacement for Finite-sum Minimax Optimization](https://proceedings.neurips.cc/paper_files/paper/2022/hash/2ce4f0b8e24c45318352068603153590-Abstract-Conference.html) accepted at **NeurIPS 2022** 
- **[Jul. 2022]** Joined the MLO Team at Google DeepMind
- **[Jun. 2022]** Graduated from IIT Kanpur with a Double Major in EE and Math.

## Selected Publications

- **Provably Fast Finite-Particle Variants of SVGD via Virtual Particle Stochastic Approximation**  
*with Dheeraj Nagaraj*  
**Spotlight** at NeurIPS 2023 [**[Paper]**](https://arxiv.org/abs/2305.17558)  
**Oral Presentation** at [OTML Workshop, NeurIPS 2023](https://otmlworkshop.github.io/)

- **Utilising the CLT Structure in Stochastic Gradient based Sampling : Improved Analysis and Faster Algorithms**  
*with Dheeraj Nagaraj and Anant Raj*  
COLT 2023 [**[Paper]**](https://proceedings.mlr.press/v195/das23b.html)

- **Near Optimal Heteroscedastic Regression with Symbiotic Learning**  
*with Dheeraj Baby, Dheeraj Nagaraj and Praneeth Netrapalli*  
COLT 2023 [**[Paper]**](https://proceedings.mlr.press/v195/das23a.html)

- **Sampling without Replacement Leads to Faster Rates in Finite-Sum Minimax Optimization**  
*with Bernhard Schölkopf and Michael Muehlebach*  
NeurIPS 2022 [**[Paper]**](https://proceedings.neurips.cc/paper_files/paper/2022/hash/2ce4f0b8e24c45318352068603153590-Abstract-Conference.html)

## Service

- Reviewer : NeurIPS, AISTATS
- Co-ordinator : Special Interest Group in Machine Learning, IIT Kanpur
- Undergrad Mentor : Programming Club, IIT Kanpur and Stamatics (Math Club), IIT Kanpur


